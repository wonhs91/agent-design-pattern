{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439074d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent hierarchy created successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import LlmAgent, BaseAgent\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from google.adk.events import Event\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "# Correctly implement a custom agent by extending BaseAgent\n",
    "class TaskExecutor(BaseAgent):\n",
    "   \"\"\"A specialized agent with custom, non-LLM behavior.\"\"\"\n",
    "   name: str = \"TaskExecutor\"\n",
    "   description: str = \"Executes a predefined task.\"\n",
    "\n",
    "   async def _run_async_impl(self, context: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "       \"\"\"Custom implementation logic for the task.\"\"\"\n",
    "       # This is where your custom logic would go.\n",
    "       # For this example, we'll just yield a simple event.\n",
    "       yield Event(author=self.name, content=\"Task finished successfully.\")\n",
    "\n",
    "# Define individual agents with proper initialization\n",
    "# LlmAgent requires a model to be specified.\n",
    "greeter = LlmAgent(\n",
    "   name=\"Greeter\",\n",
    "   model=\"gemini-2.0-flash-exp\",\n",
    "   instruction=\"You are a friendly greeter.\"\n",
    ")\n",
    "task_doer = TaskExecutor() # Instantiate our concrete custom agent\n",
    "\n",
    "# Create a parent agent and assign its sub-agents\n",
    "# The parent agent's description and instructions should guide its delegation logic.\n",
    "coordinator = LlmAgent(\n",
    "   name=\"Coordinator\",\n",
    "   model=\"gemini-2.0-flash-exp\",\n",
    "   description=\"A coordinator that can greet users and execute tasks.\",\n",
    "   instruction=\"When asked to greet, delegate to the Greeter. When asked to perform a task, delegate to the TaskExecutor.\",\n",
    "   sub_agents=[\n",
    "       greeter,\n",
    "       task_doer\n",
    "   ]\n",
    ")\n",
    "\n",
    "# The ADK framework automatically establishes the parent-child relationships.\n",
    "# These assertions will pass if checked after initialization.\n",
    "assert greeter.parent_agent == coordinator\n",
    "assert task_doer.parent_agent == coordinator\n",
    "\n",
    "print(\"Agent hierarchy created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa87fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import AsyncGenerator\n",
    "from google.adk.agents import LoopAgent, LlmAgent, BaseAgent\n",
    "from google.adk.events import Event, EventActions\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "\n",
    "# Best Practice: Define custom agents as complete, self-describing classes.\n",
    "class ConditionChecker(BaseAgent):\n",
    "   \"\"\"A custom agent that checks for a 'completed' status in the session state.\"\"\"\n",
    "   name: str = \"ConditionChecker\"\n",
    "   description: str = \"Checks if a process is complete and signals the loop to stop.\"\n",
    "\n",
    "   async def _run_async_impl(\n",
    "       self, context: InvocationContext\n",
    "   ) -> AsyncGenerator[Event, None]:\n",
    "       \"\"\"Checks state and yields an event to either continue or stop the loop.\"\"\"\n",
    "       status = context.session.state.get(\"status\", \"pending\")\n",
    "       is_done = (status == \"completed\")\n",
    "\n",
    "       if is_done:\n",
    "           # Escalate to terminate the loop when the condition is met.\n",
    "           yield Event(author=self.name, actions=EventActions(escalate=True))\n",
    "       else:\n",
    "           # Yield a simple event to continue the loop.\n",
    "           yield Event(author=self.name, content=\"Condition not met, continuing loop.\")\n",
    "\n",
    "# Correction: The LlmAgent must have a model and clear instructions.\n",
    "process_step = LlmAgent(\n",
    "   name=\"ProcessingStep\",\n",
    "   model=\"gemini-2.0-flash-exp\",\n",
    "   instruction=\"You are a step in a longer process. Perform your task. If you are the final step, update session state by setting 'status' to 'completed'.\"\n",
    ")\n",
    "\n",
    "# The LoopAgent orchestrates the workflow.\n",
    "poller = LoopAgent(\n",
    "   name=\"StatusPoller\",\n",
    "   max_iterations=10,\n",
    "   sub_agents=[\n",
    "       process_step,\n",
    "       ConditionChecker() # Instantiating the well-defined custom agent.\n",
    "   ]\n",
    ")\n",
    "\n",
    "# This poller will now execute 'process_step' \n",
    "# and then 'ConditionChecker'\n",
    "# repeatedly until the status is 'completed' or 10 iterations \n",
    "# have passed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9541d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import agent_tool\n",
    "from google.genai import types\n",
    "\n",
    "# 1. A simple function tool for the core capability.\n",
    "# This follows the best practice of separating actions from reasoning.\n",
    "def generate_image(prompt: str) -> dict:\n",
    "   \"\"\"\n",
    "   Generates an image based on a textual prompt.\n",
    "\n",
    "   Args:\n",
    "       prompt: A detailed description of the image to generate.\n",
    "\n",
    "   Returns:\n",
    "       A dictionary with the status and the generated image bytes.\n",
    "   \"\"\"\n",
    "   print(f\"TOOL: Generating image for prompt: '{prompt}'\")\n",
    "   # In a real implementation, this would call an image generation API.\n",
    "   # For this example, we return mock image data.\n",
    "   mock_image_bytes = b\"mock_image_data_for_a_cat_wearing_a_hat\"\n",
    "   return {\n",
    "       \"status\": \"success\",\n",
    "       # The tool returns the raw bytes, the agent will handle the Part creation.\n",
    "       \"image_bytes\": mock_image_bytes,\n",
    "       \"mime_type\": \"image/png\"\n",
    "   }\n",
    "\n",
    "# 2. Refactor the ImageGeneratorAgent into an LlmAgent.\n",
    "# It now correctly uses the input passed to it.\n",
    "image_generator_agent = LlmAgent(\n",
    "   name=\"ImageGen\",\n",
    "   model=\"gemini-2.0-flash\",\n",
    "   description=\"Generates an image based on a detailed text prompt.\",\n",
    "   instruction=(\n",
    "       \"You are an image generation specialist. Your task is to take the user's request \"\n",
    "       \"and use the `generate_image` tool to create the image. \"\n",
    "       \"The user's entire request should be used as the 'prompt' argument for the tool. \"\n",
    "       \"After the tool returns the image bytes, you MUST output the image.\"\n",
    "   ),\n",
    "   tools=[generate_image]\n",
    ")\n",
    "\n",
    "# 3. Wrap the corrected agent in an AgentTool.\n",
    "# The description here is what the parent agent sees.\n",
    "image_tool = agent_tool.AgentTool(\n",
    "   agent=image_generator_agent,\n",
    "#    description=\"Use this tool to generate an image. The input should be a descriptive prompt of the desired image.\"\n",
    ")\n",
    "\n",
    "# 4. The parent agent remains unchanged. Its logic was correct.\n",
    "artist_agent = LlmAgent(\n",
    "   name=\"Artist\",\n",
    "   model=\"gemini-2.0-flash\",\n",
    "   instruction=(\n",
    "       \"You are a creative artist. First, invent a creative and descriptive prompt for an image. \"\n",
    "       \"Then, use the `ImageGen` tool to generate the image using your prompt.\"\n",
    "   ),\n",
    "   tools=[image_tool]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
